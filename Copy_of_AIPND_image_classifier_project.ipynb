{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clencyc/Image-Classifier-AWS/blob/main/Copy_of_AIPND_image_classifier_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMzxj9magU5e"
      },
      "source": [
        "## AI Programming with Python Nanodegree: Image Classifier Project\n",
        "  - Do not make changes to the first 2 code cells, they are being used for setting up the `flowers` dataset and `cat_to_name.json`. Start writing code from third code cell onwards.\n",
        "  - To use this notebook: `File > Save a copy in Drive`\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EUKirN80Na6"
      },
      "source": [
        "### Code Explanation:\n",
        "\n",
        "- **Setting Up Flower Dataset:**\n",
        "  - `data_dir = './flowers'`: Defines the directory path for the flower dataset.\n",
        "  - `FLOWERS_DIR = Path(data_dir)`: Uses `Path` from `pathlib` for handling PosixPath.\n",
        "\n",
        "- **Downloading and Extracting Dataset:**\n",
        "  - `if not FLOWERS_DIR.is_dir()`: Checks if the dataset directory exists.\n",
        "    - `FLOWERS_DIR.mkdir(parents=True, exist_ok=True)`: Creates the directory if not present.\n",
        "  - `TARBALL = FLOWERS_DIR / \"flower_data.tar.gz\"`: Defines the tarball path.\n",
        "  - Downloads and extracts the dataset if not already present:\n",
        "    - `request = requests.get(...)`: Downloads the 'flower_data.tar.gz' file.\n",
        "    - `with open(TARBALL, \"wb\") as file_ref`: Writes the downloaded content to the tarball.\n",
        "    - `with tarfile.open(TARBALL, \"r\") as tar_ref`: Extracts the tarball contents to the dataset directory.\n",
        "\n",
        "- **Cleaning Up:**\n",
        "  - `os.remove(TARBALL)`: Deletes the downloaded tarball to save space.\n",
        "\n",
        "- **Status Messages:**\n",
        "  - Prints informative messages about the directory creation, download, extraction, and cleanup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFHu1nUUE_PF",
        "outputId": "85ed36a2-41e0-44b6-e987-830af573ec36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Directory created: ./flowers\n",
            "\n",
            "[INFO] Downloading the file 'flower_data.tar.gz' to ./flowers\n",
            "[INFO] 'flower_data.tar.gz' saved to ./flowers\n",
            "\n",
            "[INFO] Extracting the downloaded tarball to ./flowers\n",
            "[INFO] 'flower_data.tar.gz' extracted successfully to ./flowers\n",
            "\n",
            "[INFO] Deleting the tarball to save space.\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import os\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import tarfile\n",
        "\n",
        "# defining dataset directory\n",
        "data_dir = './flowers'\n",
        "\n",
        "# using pathlib.Path for handling PosixPath\n",
        "FLOWERS_DIR = Path(data_dir)\n",
        "\n",
        "# downloading and setting up data if not already present\n",
        "if not FLOWERS_DIR.is_dir():\n",
        "    # creating directory\n",
        "    FLOWERS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"[INFO] Directory created: ./{FLOWERS_DIR}\")\n",
        "\n",
        "    print() # for readability\n",
        "\n",
        "    # tarball path\n",
        "    TARBALL = FLOWERS_DIR / \"flower_data.tar.gz\"\n",
        "\n",
        "    # downloading and writing the tarball to './flowers' directory\n",
        "    print(f\"[INFO] Downloading the file 'flower_data.tar.gz' to ./{FLOWERS_DIR}\")\n",
        "    request = requests.get('https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz')\n",
        "    with open(TARBALL, \"wb\") as file_ref:\n",
        "        file_ref.write(request.content)\n",
        "        print(f\"[INFO] 'flower_data.tar.gz' saved to ./{FLOWERS_DIR}\")\n",
        "\n",
        "    print() # for readability\n",
        "\n",
        "    # extracting the downloaded tarball\n",
        "    print(f\"[INFO] Extracting the downloaded tarball to ./{FLOWERS_DIR}\")\n",
        "    with tarfile.open(TARBALL, \"r\") as tar_ref:\n",
        "        tar_ref.extractall(FLOWERS_DIR)\n",
        "        print(f\"[INFO] 'flower_data.tar.gz' extracted successfully to ./{FLOWERS_DIR}\")\n",
        "\n",
        "    print() # for readability\n",
        "\n",
        "    # using os.remove to delete the downloaded tarball\n",
        "    print(\"[INFO] Deleting the tarball to save space.\")\n",
        "    os.remove(TARBALL)\n",
        "else:\n",
        "    print(f\"[INFO] Dataset already setup at ./{FLOWERS_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsRLKv2u0ard"
      },
      "source": [
        "### Code Explanation:\n",
        "\n",
        "- **Creating a JSON File for Flower Categories:**\n",
        "  - `data`: Defines a dictionary containing numerical keys and corresponding flower names.\n",
        "  - `with open('cat_to_name.json', 'w') as file`: Opens the file 'cat_to_name.json' for writing.\n",
        "  - `json.dump(data, file)`: Writes the dictionary data to the JSON file.\n",
        "\n",
        "- **Interpreting the Output:**\n",
        "  - The code creates a JSON file named 'cat_to_name.json' that serves as a mapping between numerical keys and flower names. This mapping can be useful for associating numerical labels with human-readable names in machine learning tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6378UAqFK_t"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "data = {\n",
        "    \"21\": \"fire lily\", \"3\": \"canterbury bells\", \"45\": \"bolero deep blue\", \"1\": \"pink primrose\", \"34\": \"mexican aster\",\n",
        "    \"27\": \"prince of wales feathers\", \"7\": \"moon orchid\", \"16\": \"globe-flower\", \"25\": \"grape hyacinth\", \"26\": \"corn poppy\",\n",
        "    \"79\": \"toad lily\", \"39\": \"siam tulip\", \"24\": \"red ginger\", \"67\": \"spring crocus\", \"35\": \"alpine sea holly\",\n",
        "    \"32\": \"garden phlox\", \"10\": \"globe thistle\", \"6\": \"tiger lily\", \"93\": \"ball moss\", \"33\": \"love in the mist\",\n",
        "    \"9\": \"monkshood\", \"102\": \"blackberry lily\", \"14\": \"spear thistle\", \"19\": \"balloon flower\", \"100\": \"blanket flower\",\n",
        "    \"13\": \"king protea\", \"49\": \"oxeye daisy\", \"15\": \"yellow iris\", \"61\": \"cautleya spicata\", \"31\": \"carnation\",\n",
        "    \"64\": \"silverbush\", \"68\": \"bearded iris\", \"63\": \"black-eyed susan\", \"69\": \"windflower\", \"62\": \"japanese anemone\",\n",
        "    \"20\": \"giant white arum lily\", \"38\": \"great masterwort\", \"4\": \"sweet pea\", \"86\": \"tree mallow\",\n",
        "    \"101\": \"trumpet creeper\", \"42\": \"daffodil\", \"22\": \"pincushion flower\", \"2\": \"hard-leaved pocket orchid\",\n",
        "    \"54\": \"sunflower\", \"66\": \"osteospermum\", \"70\": \"tree poppy\", \"85\": \"desert-rose\", \"99\": \"bromelia\", \"87\": \"magnolia\",\n",
        "    \"5\": \"english marigold\", \"92\": \"bee balm\", \"28\": \"stemless gentian\", \"97\": \"mallow\", \"57\": \"gaura\",\n",
        "    \"40\": \"lenten rose\", \"47\": \"marigold\", \"59\": \"orange dahlia\", \"48\": \"buttercup\", \"55\": \"pelargonium\",\n",
        "    \"36\": \"ruby-lipped cattleya\", \"91\": \"hippeastrum\", \"29\": \"artichoke\", \"71\": \"gazania\", \"90\": \"canna lily\",\n",
        "    \"18\": \"peruvian lily\", \"98\": \"mexican petunia\", \"8\": \"bird of paradise\", \"30\": \"sweet william\",\n",
        "    \"17\": \"purple coneflower\", \"52\": \"wild pansy\", \"84\": \"columbine\", \"12\": \"colt's foot\", \"11\": \"snapdragon\",\n",
        "    \"96\": \"camellia\", \"23\": \"fritillary\", \"50\": \"common dandelion\", \"44\": \"poinsettia\", \"53\": \"primula\",\n",
        "    \"72\": \"azalea\", \"65\": \"californian poppy\", \"80\": \"anthurium\", \"76\": \"morning glory\", \"37\": \"cape flower\",\n",
        "    \"56\": \"bishop of llandaff\", \"60\": \"pink-yellow dahlia\", \"82\": \"clematis\", \"58\": \"geranium\", \"75\": \"thorn apple\",\n",
        "    \"41\": \"barbeton daisy\", \"95\": \"bougainvillea\", \"43\": \"sword lily\", \"83\": \"hibiscus\", \"78\": \"lotus lotus\",\n",
        "    \"88\": \"cyclamen\", \"94\": \"foxglove\", \"81\": \"frangipani\", \"74\": \"rose\", \"89\": \"watercress\", \"73\": \"water lily\",\n",
        "    \"46\": \"wallflower\", \"77\": \"passion flower\", \"51\": \"petunia\"\n",
        "}\n",
        "\n",
        "with open('cat_to_name.json', 'w') as file:\n",
        "    json.dump(data, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5UZpVNNG17Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDpOnX7_ju3f"
      },
      "outputs": [],
      "source": [
        "def data_transforms():\n",
        "  # defining transformations for training and validation sets\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # both are imageNet normalizations\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    return train_transform, val_transform\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45PTFeyEitOl"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "def load_data(data_dir):\n",
        "  train_transform, val_transform = data_transforms()\n",
        "\n",
        "  # loading the datasets with ImageFolder\n",
        "  train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transform)\n",
        "  val_data = datasets.ImageFolder(root=f\"{data_dir}/valid\", transform=val_transform)\n",
        "\n",
        "  return train_data, val_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwLg5xY3jpcq"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def create_dataloaders(train_dataset, val_dataset, batch_size=32):\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  return train_loader, val_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO1dOcsPnsx1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "def build_model(pretrained=True):\n",
        "    model = models.resnet34(pretrained=pretrained)\n",
        "\n",
        "    # Print output shape to verify before modifying FC layer\n",
        "    sample_input = torch.randn((1, 3, 224, 224))\n",
        "    model(sample_input)\n",
        "\n",
        "    features = model.avgpool(model.layer4(model.layer3(model.layer2(model.layer1(model.conv1(sample_input))))))\n",
        "    features = torch.flatten(features, start_dim=1)\n",
        "\n",
        "    print(features.shape)\n",
        "\n",
        "    # Freeze all layers except the final FC layer\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Fix FC layer to match correct feature size\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(512, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 102)\n",
        "    )\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "no6HXsmYpOes"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=5, learning_rate=1e-3):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct += torch.sum(preds == labels.data)\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        accuracy = correct.double() / len(val_loader.dataset)\n",
        "        print(f\"Validation Loss: {val_loss}, Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZZtqUe2pf4H",
        "outputId": "5363e30d-22c3-4b7f-e588-c3c53c8798b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512])\n",
            "Epoch 1/5, Loss: 3.1088268024165457\n",
            "Validation Loss: 1.5123875737190247, Accuracy: 0.6039119804400978\n",
            "Epoch 2/5, Loss: 1.375925622916803\n",
            "Validation Loss: 0.9329515500710561, Accuracy: 0.7493887530562348\n",
            "Epoch 3/5, Loss: 1.0085579870677577\n",
            "Validation Loss: 0.7335206837608264, Accuracy: 0.78239608801956\n",
            "Epoch 4/5, Loss: 0.8743612164404334\n",
            "Validation Loss: 0.8132158586612115, Accuracy: 0.7689486552567237\n",
            "Epoch 5/5, Loss: 0.7572369242586741\n",
            "Validation Loss: 0.6151800233011062, Accuracy: 0.8325183374083129\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    # data_dir = \"{FLOWERS_DIR}\"\n",
        "    train_data, val_data = load_data(data_dir)\n",
        "    train_loader, val_loader = create_dataloaders(train_data, val_data, batch_size=32)\n",
        "\n",
        "    model = build_model(pretrained=True)\n",
        "    train_model(model, train_loader, val_loader, num_epochs=5, learning_rate=1e-3)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}