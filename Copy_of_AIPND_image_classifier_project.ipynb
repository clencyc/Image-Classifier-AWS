{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clencyc/Image-Classifier-AWS/blob/main/Copy_of_AIPND_image_classifier_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMzxj9magU5e"
      },
      "source": [
        "## AI Programming with Python Nanodegree: Image Classifier Project\n",
        "  - Do not make changes to the first 2 code cells, they are being used for setting up the `flowers` dataset and `cat_to_name.json`. Start writing code from third code cell onwards.\n",
        "  - To use this notebook: `File > Save a copy in Drive`\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EUKirN80Na6"
      },
      "source": [
        "### Code Explanation:\n",
        "\n",
        "- **Setting Up Flower Dataset:**\n",
        "  - `data_dir = './flowers'`: Defines the directory path for the flower dataset.\n",
        "  - `FLOWERS_DIR = Path(data_dir)`: Uses `Path` from `pathlib` for handling PosixPath.\n",
        "\n",
        "- **Downloading and Extracting Dataset:**\n",
        "  - `if not FLOWERS_DIR.is_dir()`: Checks if the dataset directory exists.\n",
        "    - `FLOWERS_DIR.mkdir(parents=True, exist_ok=True)`: Creates the directory if not present.\n",
        "  - `TARBALL = FLOWERS_DIR / \"flower_data.tar.gz\"`: Defines the tarball path.\n",
        "  - Downloads and extracts the dataset if not already present:\n",
        "    - `request = requests.get(...)`: Downloads the 'flower_data.tar.gz' file.\n",
        "    - `with open(TARBALL, \"wb\") as file_ref`: Writes the downloaded content to the tarball.\n",
        "    - `with tarfile.open(TARBALL, \"r\") as tar_ref`: Extracts the tarball contents to the dataset directory.\n",
        "\n",
        "- **Cleaning Up:**\n",
        "  - `os.remove(TARBALL)`: Deletes the downloaded tarball to save space.\n",
        "\n",
        "- **Status Messages:**\n",
        "  - Prints informative messages about the directory creation, download, extraction, and cleanup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFHu1nUUE_PF",
        "outputId": "85ed36a2-41e0-44b6-e987-830af573ec36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Dataset already setup at ./flowers\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import os\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import tarfile\n",
        "\n",
        "# defining dataset directory\n",
        "data_dir = './flowers'\n",
        "\n",
        "# using pathlib.Path for handling PosixPath\n",
        "FLOWERS_DIR = Path(data_dir)\n",
        "\n",
        "# downloading and setting up data if not already present\n",
        "if not FLOWERS_DIR.is_dir():\n",
        "    # creating directory\n",
        "    FLOWERS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"[INFO] Directory created: ./{FLOWERS_DIR}\")\n",
        "\n",
        "    print() # for readability\n",
        "\n",
        "    # tarball path\n",
        "    TARBALL = FLOWERS_DIR / \"flower_data.tar.gz\"\n",
        "\n",
        "    # downloading and writing the tarball to './flowers' directory\n",
        "    print(f\"[INFO] Downloading the file 'flower_data.tar.gz' to ./{FLOWERS_DIR}\")\n",
        "    request = requests.get('https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz')\n",
        "    with open(TARBALL, \"wb\") as file_ref:\n",
        "        file_ref.write(request.content)\n",
        "        print(f\"[INFO] 'flower_data.tar.gz' saved to ./{FLOWERS_DIR}\")\n",
        "\n",
        "    print() # for readability\n",
        "\n",
        "    # extracting the downloaded tarball\n",
        "    print(f\"[INFO] Extracting the downloaded tarball to ./{FLOWERS_DIR}\")\n",
        "    with tarfile.open(TARBALL, \"r\") as tar_ref:\n",
        "        tar_ref.extractall(FLOWERS_DIR)\n",
        "        print(f\"[INFO] 'flower_data.tar.gz' extracted successfully to ./{FLOWERS_DIR}\")\n",
        "\n",
        "    print() # for readability\n",
        "\n",
        "    # using os.remove to delete the downloaded tarball\n",
        "    print(\"[INFO] Deleting the tarball to save space.\")\n",
        "    os.remove(TARBALL)\n",
        "else:\n",
        "    print(f\"[INFO] Dataset already setup at ./{FLOWERS_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsRLKv2u0ard"
      },
      "source": [
        "### Code Explanation:\n",
        "\n",
        "- **Creating a JSON File for Flower Categories:**\n",
        "  - `data`: Defines a dictionary containing numerical keys and corresponding flower names.\n",
        "  - `with open('cat_to_name.json', 'w') as file`: Opens the file 'cat_to_name.json' for writing.\n",
        "  - `json.dump(data, file)`: Writes the dictionary data to the JSON file.\n",
        "\n",
        "- **Interpreting the Output:**\n",
        "  - The code creates a JSON file named 'cat_to_name.json' that serves as a mapping between numerical keys and flower names. This mapping can be useful for associating numerical labels with human-readable names in machine learning tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m6378UAqFK_t"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "data = {\n",
        "    \"21\": \"fire lily\", \"3\": \"canterbury bells\", \"45\": \"bolero deep blue\", \"1\": \"pink primrose\", \"34\": \"mexican aster\",\n",
        "    \"27\": \"prince of wales feathers\", \"7\": \"moon orchid\", \"16\": \"globe-flower\", \"25\": \"grape hyacinth\", \"26\": \"corn poppy\",\n",
        "    \"79\": \"toad lily\", \"39\": \"siam tulip\", \"24\": \"red ginger\", \"67\": \"spring crocus\", \"35\": \"alpine sea holly\",\n",
        "    \"32\": \"garden phlox\", \"10\": \"globe thistle\", \"6\": \"tiger lily\", \"93\": \"ball moss\", \"33\": \"love in the mist\",\n",
        "    \"9\": \"monkshood\", \"102\": \"blackberry lily\", \"14\": \"spear thistle\", \"19\": \"balloon flower\", \"100\": \"blanket flower\",\n",
        "    \"13\": \"king protea\", \"49\": \"oxeye daisy\", \"15\": \"yellow iris\", \"61\": \"cautleya spicata\", \"31\": \"carnation\",\n",
        "    \"64\": \"silverbush\", \"68\": \"bearded iris\", \"63\": \"black-eyed susan\", \"69\": \"windflower\", \"62\": \"japanese anemone\",\n",
        "    \"20\": \"giant white arum lily\", \"38\": \"great masterwort\", \"4\": \"sweet pea\", \"86\": \"tree mallow\",\n",
        "    \"101\": \"trumpet creeper\", \"42\": \"daffodil\", \"22\": \"pincushion flower\", \"2\": \"hard-leaved pocket orchid\",\n",
        "    \"54\": \"sunflower\", \"66\": \"osteospermum\", \"70\": \"tree poppy\", \"85\": \"desert-rose\", \"99\": \"bromelia\", \"87\": \"magnolia\",\n",
        "    \"5\": \"english marigold\", \"92\": \"bee balm\", \"28\": \"stemless gentian\", \"97\": \"mallow\", \"57\": \"gaura\",\n",
        "    \"40\": \"lenten rose\", \"47\": \"marigold\", \"59\": \"orange dahlia\", \"48\": \"buttercup\", \"55\": \"pelargonium\",\n",
        "    \"36\": \"ruby-lipped cattleya\", \"91\": \"hippeastrum\", \"29\": \"artichoke\", \"71\": \"gazania\", \"90\": \"canna lily\",\n",
        "    \"18\": \"peruvian lily\", \"98\": \"mexican petunia\", \"8\": \"bird of paradise\", \"30\": \"sweet william\",\n",
        "    \"17\": \"purple coneflower\", \"52\": \"wild pansy\", \"84\": \"columbine\", \"12\": \"colt's foot\", \"11\": \"snapdragon\",\n",
        "    \"96\": \"camellia\", \"23\": \"fritillary\", \"50\": \"common dandelion\", \"44\": \"poinsettia\", \"53\": \"primula\",\n",
        "    \"72\": \"azalea\", \"65\": \"californian poppy\", \"80\": \"anthurium\", \"76\": \"morning glory\", \"37\": \"cape flower\",\n",
        "    \"56\": \"bishop of llandaff\", \"60\": \"pink-yellow dahlia\", \"82\": \"clematis\", \"58\": \"geranium\", \"75\": \"thorn apple\",\n",
        "    \"41\": \"barbeton daisy\", \"95\": \"bougainvillea\", \"43\": \"sword lily\", \"83\": \"hibiscus\", \"78\": \"lotus lotus\",\n",
        "    \"88\": \"cyclamen\", \"94\": \"foxglove\", \"81\": \"frangipani\", \"74\": \"rose\", \"89\": \"watercress\", \"73\": \"water lily\",\n",
        "    \"46\": \"wallflower\", \"77\": \"passion flower\", \"51\": \"petunia\"\n",
        "}\n",
        "\n",
        "with open('cat_to_name.json', 'w') as file:\n",
        "    json.dump(data, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "N5UZpVNNG17Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rDpOnX7_ju3f"
      },
      "outputs": [],
      "source": [
        "def data_transforms():\n",
        "  # defining transformations for training and validation sets\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # both are imageNet normalizations\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    return train_transform, val_transform\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "45PTFeyEitOl"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "def load_data(data_dir):\n",
        "  train_transform, val_transform = data_transforms()\n",
        "\n",
        "  # loading the datasets with ImageFolder\n",
        "  train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transform)\n",
        "  val_data = datasets.ImageFolder(root=f\"{data_dir}/valid\", transform=val_transform)\n",
        "\n",
        "  return train_data, val_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HwLg5xY3jpcq"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def create_dataloaders(train_dataset, val_dataset, batch_size=32):\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  return train_loader, val_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qO1dOcsPnsx1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "def build_model(pretrained=True):\n",
        "    model = models.resnet34(pretrained=pretrained)\n",
        "\n",
        "    # Print output shape to verify before modifying FC layer\n",
        "    sample_input = torch.randn((1, 3, 224, 224))\n",
        "    model(sample_input)\n",
        "\n",
        "    features = model.avgpool(model.layer4(model.layer3(model.layer2(model.layer1(model.conv1(sample_input))))))\n",
        "    features = torch.flatten(features, start_dim=1)\n",
        "\n",
        "    print(features.shape)\n",
        "\n",
        "    # Freeze all layers except the final FC layer\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Fix FC layer to match correct feature size\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(512, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 102)\n",
        "    )\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "no6HXsmYpOes"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=5, learning_rate=1e-3):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct += torch.sum(preds == labels.data)\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        accuracy = correct.double() / len(val_loader.dataset)\n",
        "        print(f\"Validation Loss: {val_loss}, Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZZtqUe2pf4H",
        "outputId": "5363e30d-22c3-4b7f-e588-c3c53c8798b0"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "Couldn't find any class folder in /home/clencyc/Dev/Image-Classifier-AWS/flowers/train.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     train_model(model, train_loader, val_loader, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[18], line 3\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m      2\u001b[0m     data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/clencyc/Dev/Image-Classifier-AWS/flowers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     train_data, val_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     train_loader, val_loader \u001b[38;5;241m=\u001b[39m create_dataloaders(train_data, val_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m      6\u001b[0m     model \u001b[38;5;241m=\u001b[39m build_model(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "Cell \u001b[0;32mIn[14], line 7\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m      4\u001b[0m train_transform, val_transform \u001b[38;5;241m=\u001b[39m data_transforms()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# loading the datasets with ImageFolder\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m val_data \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mImageFolder(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/valid\u001b[39m\u001b[38;5;124m\"\u001b[39m, transform\u001b[38;5;241m=\u001b[39mval_transform)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_data, val_data\n",
            "File \u001b[0;32m~/Dev/Image-Classifier-AWS/Imageenv/lib/python3.13/site-packages/torchvision/datasets/folder.py:328\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    321\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    327\u001b[0m ):\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
            "File \u001b[0;32m~/Dev/Image-Classifier-AWS/Imageenv/lib/python3.13/site-packages/torchvision/datasets/folder.py:149\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    140\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[0;32m--> 149\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot,\n\u001b[1;32m    152\u001b[0m         class_to_idx\u001b[38;5;241m=\u001b[39mclass_to_idx,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m         allow_empty\u001b[38;5;241m=\u001b[39mallow_empty,\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
            "File \u001b[0;32m~/Dev/Image-Classifier-AWS/Imageenv/lib/python3.13/site-packages/torchvision/datasets/folder.py:234\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Dev/Image-Classifier-AWS/Imageenv/lib/python3.13/site-packages/torchvision/datasets/folder.py:43\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     41\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(directory) \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m class_to_idx \u001b[38;5;241m=\u001b[39m {cls_name: i \u001b[38;5;28;01mfor\u001b[39;00m i, cls_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes)}\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classes, class_to_idx\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in /home/clencyc/Dev/Image-Classifier-AWS/flowers/train."
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    data_dir = \"/home/clencyc/Dev/Image-Classifier-AWS/flowers\"\n",
        "    try:\n",
        "        train_data, val_data = load_data(data_dir)\n",
        "        print(\"Data loaded successfully!\")\n",
        "        print(f\"Number of training samples: {len(train_data)}\")\n",
        "        print(f\"Number of validation samples: {len(val_data)}\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Imageenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
